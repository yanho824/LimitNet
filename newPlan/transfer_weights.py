# Copyright 2024 Kiel University
#
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.

import torch
import argparse
import os
import sys
from collections import OrderedDict

# æ·»åŠ æ ¹ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥modelsæ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(current_dir)  # LimitNetæ ¹ç›®å½•
sys.path.insert(0, root_dir)

print(f"ğŸ”§ æ·»åŠ æ¨¡å—æœç´¢è·¯å¾„: {root_dir}")

# ç°åœ¨åº”è¯¥å¯ä»¥æˆåŠŸå¯¼å…¥modelsæ¨¡å—
try:
    from models.model import LimitNet  # å¯¼å…¥åŸå§‹LimitNetç±»
    print("âœ… æˆåŠŸå¯¼å…¥åŸå§‹LimitNetç±»")
except ImportError as e:
    print(f"âš ï¸  æ— æ³•å¯¼å…¥åŸå§‹LimitNetç±»: {e}")

from limitnet_with_detection import LimitNetWithDetection


def parse_args():
    parser = argparse.ArgumentParser(description='Transfer weights from original LimitNet to Detection version')
    parser.add_argument('--original_model_path', type=str, required=True,
                       help='Path to original LimitNet model')
    parser.add_argument('--output_path', type=str, required=True,
                       help='Output path for new model with transferred weights')
    parser.add_argument('--model_type', type=str, choices=['cifar', 'imagenet'], default='cifar',
                       help='Model type')
    parser.add_argument('--device', type=str, default='cuda',
                       help='Device to use')
    
    return parser.parse_args()


def load_original_model(model_path, device='cuda'):
    """åŠ è½½åŸå§‹LimitNetæ¨¡å‹ - æ”¯æŒå¤šç§æ ¼å¼å’Œé”™è¯¯æ¢å¤"""
    print(f"åŠ è½½åŸå§‹æ¨¡å‹: {model_path}")
    
    # æ–¹æ³•1: å°è¯•weights_onlyåŠ è½½ï¼ˆè·³è¿‡æ¨¡å—ä¾èµ–ï¼‰
    try:
        print("ğŸ” æ–¹æ³•1: weights_onlyæ¨¡å¼...")
        original_state = torch.load(model_path, map_location=device, weights_only=True)
        print("âœ… æˆåŠŸåŠ è½½åŸå§‹æ¨¡å‹ (weights_only)")
        return original_state
    except Exception as e:
        print(f"âš ï¸  æ–¹æ³•1å¤±è´¥: {e}")
    
    # æ–¹æ³•2: è‡ªå®šä¹‰pickleåŠ è½½å™¨ï¼ˆè·³è¿‡modelsæ¨¡å—ï¼‰
    try:
        print("ğŸ” æ–¹æ³•2: è‡ªå®šä¹‰pickleåŠ è½½å™¨...")
        import pickle
        
        class ModelUnpickler(pickle.Unpickler):
            def find_class(self, module, name):
                # å¦‚æœé‡åˆ°modelsæ¨¡å—ç›¸å…³çš„ç±»ï¼Œè¿”å›ä¸€ä¸ªå ä½ç¬¦
                if 'models' in module:
                    return lambda *args, **kwargs: None
                return super().find_class(module, name)
        
        with open(model_path, 'rb') as f:
            original_state = ModelUnpickler(f).load()
        print("âœ… æˆåŠŸåŠ è½½åŸå§‹æ¨¡å‹ (è‡ªå®šä¹‰unpickler)")
        return original_state
    except Exception as e:
        print(f"âš ï¸  æ–¹æ³•2å¤±è´¥: {e}")
    
    # æ–¹æ³•3: å°è¯•ç›´æ¥åŠ è½½å¹¶å¿½ç•¥é”™è¯¯
    try:
        print("ğŸ” æ–¹æ³•3: ç›´æ¥åŠ è½½...")
        original_state = torch.load(model_path, map_location=device)
        print("âœ… æˆåŠŸåŠ è½½åŸå§‹æ¨¡å‹ (ç›´æ¥åŠ è½½)")
        return original_state
    except Exception as e:
        print(f"âš ï¸  æ–¹æ³•3å¤±è´¥: {e}")
    
    print(f"âŒ æ‰€æœ‰åŠ è½½æ–¹æ³•éƒ½å¤±è´¥äº†")
    return None


def extract_transferable_weights(original_state):
    """æå–å¯è¿ç§»çš„æƒé‡"""
    transferable_weights = OrderedDict()
    
    # éœ€è¦è¿ç§»çš„ç»„ä»¶
    components_to_transfer = [
        'encoder',      # ç¼–ç å™¨
        'decoder',      # è§£ç å™¨
        'cls_model'     # åˆ†ç±»å™¨
    ]
    
    print("ğŸ” åˆ†æåŸå§‹æ¨¡å‹æ ¼å¼...")
    print(f"åŸå§‹æ¨¡å‹ç±»å‹: {type(original_state)}")
    
    if isinstance(original_state, dict):
        print("ğŸ“¦ å­—å…¸æ ¼å¼ï¼Œæ£€æŸ¥å¯ç”¨é”®...")
        print(f"å¯ç”¨é”®: {list(original_state.keys())}")
        
        if 'state_dict' in original_state:
            state_dict = original_state['state_dict']
            print("âœ… æ‰¾åˆ°state_dicté”®")
        else:
            state_dict = original_state
            print("âœ… ç›´æ¥ä½¿ç”¨å­—å…¸ä½œä¸ºstate_dict")
    elif hasattr(original_state, 'state_dict'):
        print("ğŸ“¦ æ¨¡å‹å¯¹è±¡æ ¼å¼ï¼Œæå–state_dict...")
        state_dict = original_state.state_dict()
        print("âœ… æˆåŠŸæå–state_dict")
    else:
        print("âŒ æ— æ³•è§£ææ¨¡å‹çŠ¶æ€å­—å…¸")
        print(f"æ¨¡å‹å¯¹è±¡å±æ€§: {dir(original_state)[:10]}...")  # æ˜¾ç¤ºå‰10ä¸ªå±æ€§
        return None
    
    print(f"\nğŸ” åˆ†æåŸå§‹æ¨¡å‹æƒé‡... (å…±{len(state_dict)}ä¸ªå‚æ•°)")
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªé”®ä½œä¸ºç¤ºä¾‹
    sample_keys = list(state_dict.keys())[:5]
    print(f"ç¤ºä¾‹é”®: {sample_keys}")
    
    for key, value in state_dict.items():
        if hasattr(value, 'shape'):
            print(f"  - {key}: {value.shape}")
            
            # æ£€æŸ¥æ˜¯å¦å±äºå¯è¿ç§»çš„ç»„ä»¶
            for component in components_to_transfer:
                if key.startswith(component):
                    transferable_weights[key] = value
                    break
        else:
            print(f"  - {key}: {type(value)} (éå¼ é‡)")
    
    print(f"\nâœ… æ‰¾åˆ° {len(transferable_weights)} ä¸ªå¯è¿ç§»çš„æƒé‡")
    if len(transferable_weights) > 0:
        print("è¿ç§»çš„æƒé‡åŒ…æ‹¬:")
        for key in transferable_weights.keys():
            print(f"  âœ“ {key}")
    
    return transferable_weights


def create_new_model_with_weights(model_type, transferable_weights, device='cuda'):
    """åˆ›å»ºå¸¦æœ‰è¿ç§»æƒé‡çš„æ–°æ¨¡å‹"""
    print("ğŸš€ åˆ›å»ºæ–°çš„æ£€æµ‹è¿½è¸ªæ¨¡å‹...")
    
    # é…ç½®æ£€æµ‹å™¨ï¼ˆä½¿ç”¨ç®€å•é…ç½®é¿å…ä¾èµ–é—®é¢˜ï¼‰
    detector_config = {
        'model_path': 'yolo11n.pt',
        'conf_threshold': 0.25,
        'iou_threshold': 0.45,
        'device': device
    }
    
    # åˆ›å»ºæ–°æ¨¡å‹
    new_model = LimitNetWithDetection(
        model_type=model_type,
        detector_config=detector_config
    )
    
    # è·å–æ–°æ¨¡å‹çš„çŠ¶æ€å­—å…¸
    new_state_dict = new_model.state_dict()
    
    # è¿ç§»æƒé‡
    transferred_count = 0
    skipped_count = 0
    
    print("\nğŸ”„ è¿ç§»æƒé‡...")
    for key, value in transferable_weights.items():
        if key in new_state_dict:
            if new_state_dict[key].shape == value.shape:
                new_state_dict[key] = value
                transferred_count += 1
                print(f"  âœ… {key}: {value.shape}")
            else:
                print(f"  âš ï¸  {key}: å½¢çŠ¶ä¸åŒ¹é… {new_state_dict[key].shape} vs {value.shape}")
                skipped_count += 1
        else:
            print(f"  âŒ {key}: åœ¨æ–°æ¨¡å‹ä¸­ä¸å­˜åœ¨")
            skipped_count += 1
    
    # åŠ è½½æ–°çš„çŠ¶æ€å­—å…¸
    new_model.load_state_dict(new_state_dict)
    
    print(f"\nğŸ“Š è¿ç§»ç»Ÿè®¡:")
    print(f"  - æˆåŠŸè¿ç§»: {transferred_count} ä¸ªæƒé‡")
    print(f"  - è·³è¿‡: {skipped_count} ä¸ªæƒé‡")
    print(f"  - è¿ç§»æ¯”ä¾‹: {transferred_count/(transferred_count+skipped_count)*100:.1f}%")
    
    return new_model


def analyze_model_differences(original_state, new_model):
    """åˆ†ææ¨¡å‹å·®å¼‚"""
    print("\nğŸ” æ¨¡å‹å·®å¼‚åˆ†æ:")
    
    if isinstance(original_state, dict):
        if 'state_dict' in original_state:
            original_keys = set(original_state['state_dict'].keys())
        else:
            original_keys = set(original_state.keys())
    else:
        print("âŒ æ— æ³•åˆ†æåŸå§‹æ¨¡å‹")
        return
    
    new_keys = set(new_model.state_dict().keys())
    
    # åŸå§‹æ¨¡å‹æœ‰ä½†æ–°æ¨¡å‹æ²¡æœ‰çš„
    only_in_original = original_keys - new_keys
    if only_in_original:
        print("\nâŒ ä»…åœ¨åŸå§‹æ¨¡å‹ä¸­å­˜åœ¨ï¼ˆå°†è¢«ä¸¢å¼ƒï¼‰:")
        for key in sorted(only_in_original):
            print(f"  - {key}")
    
    # æ–°æ¨¡å‹æœ‰ä½†åŸå§‹æ¨¡å‹æ²¡æœ‰çš„
    only_in_new = new_keys - original_keys
    if only_in_new:
        print("\nğŸ†• ä»…åœ¨æ–°æ¨¡å‹ä¸­å­˜åœ¨ï¼ˆå°†éšæœºåˆå§‹åŒ–ï¼‰:")
        for key in sorted(only_in_new):
            print(f"  - {key}")
    
    # å…±åŒå­˜åœ¨çš„
    common_keys = original_keys & new_keys
    print(f"\nâœ… å…±åŒå­˜åœ¨ï¼ˆå¯ä»¥è¿ç§»ï¼‰: {len(common_keys)} ä¸ªæƒé‡")


def save_model(model, output_path, additional_info=None):
    """ä¿å­˜æ¨¡å‹"""
    print(f"\nğŸ’¾ ä¿å­˜æ¨¡å‹è‡³: {output_path}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    # å‡†å¤‡ä¿å­˜çš„æ•°æ®
    save_data = {
        'state_dict': model.state_dict(),
        'model_type': model.hparams.get('model_type', 'unknown') if hasattr(model, 'hparams') else 'unknown',
        'transfer_info': additional_info or {}
    }
    
    torch.save(save_data, output_path)
    print("âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ!")


def main():
    args = parse_args()
    
    print("ğŸ¯ LimitNetæƒé‡è¿ç§»å·¥å…·")
    print("ä»åŸå§‹LimitNetè¿ç§»ç¼–ç å™¨å’Œè§£ç å™¨æƒé‡åˆ°æ£€æµ‹è¿½è¸ªç‰ˆæœ¬")
    
    # è®¾ç½®è®¾å¤‡
    device = args.device if torch.cuda.is_available() and args.device == 'cuda' else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½åŸå§‹æ¨¡å‹
    original_state = load_original_model(args.original_model_path, device)
    if original_state is None:
        print("âŒ æ— æ³•åŠ è½½åŸå§‹æ¨¡å‹ï¼Œé€€å‡º...")
        return
    
    # æå–å¯è¿ç§»çš„æƒé‡
    transferable_weights = extract_transferable_weights(original_state)
    if transferable_weights is None or len(transferable_weights) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯è¿ç§»çš„æƒé‡ï¼Œé€€å‡º...")
        return
    
    # åˆ›å»ºæ–°æ¨¡å‹å¹¶è¿ç§»æƒé‡
    try:
        new_model = create_new_model_with_weights(args.model_type, transferable_weights, device)
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ–°æ¨¡å‹å¤±è´¥: {e}")
        return
    
    # åˆ†ææ¨¡å‹å·®å¼‚
    analyze_model_differences(original_state, new_model)
    
    # ä¿å­˜æ–°æ¨¡å‹
    transfer_info = {
        'original_model_path': args.original_model_path,
        'transfer_timestamp': torch.tensor(torch.initial_seed()),  # ç®€å•çš„æ—¶é—´æˆ³
        'transferred_components': ['encoder', 'decoder', 'cls_model']
    }
    
    save_model(new_model, args.output_path, transfer_info)
    
    print("\nğŸ‰ æƒé‡è¿ç§»å®Œæˆ!")
    print("\nğŸ“‹ ä¸‹ä¸€æ­¥:")
    print(f"1. ä½¿ç”¨è¿ç§»åçš„æ¨¡å‹å¼€å§‹è®­ç»ƒ:")
    print(f"   python train_with_detection.py --resume_from {args.output_path}")
    print("2. ç”±äºæ£€æµ‹æœºåˆ¶æ”¹å˜ï¼Œå»ºè®®:")
    print("   - é˜¶æ®µ1: ä½¿ç”¨è¾ƒå°‘çš„epochs (10-20)")
    print("   - é˜¶æ®µ2: é‡ç‚¹è®­ç»ƒæ£€æµ‹-é‡å»ºé…åˆ (20-30 epochs)")
    print("   - é˜¶æ®µ3: å¾®è°ƒåˆ†ç±»æ€§èƒ½ (10-20 epochs)")


if __name__ == "__main__":
    main() 