# Copyright 2024 Kiel University
#
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.

import argparse
import torch
import torch.nn as nn
import lightning as L
from lightning.pytorch.loggers import WandbLogger
from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint
import torchvision
from torchvision import transforms
from torch.utils.data import DataLoader
import os

from limitnet_with_detection import LimitNetWithDetection


def parse_args():
    parser = argparse.ArgumentParser(description='Train LimitNet with Detection Tracking')
    
    # æ¨¡å‹é…ç½®
    parser.add_argument('--model', type=str, choices=['cifar', 'imagenet'], default='cifar',
                       help='Model type: cifar or imagenet')
    parser.add_argument('--batch_size', type=int, default=32, help='Batch size')
    parser.add_argument('--learning_rate', type=float, default=0.001, help='Learning rate')
    parser.add_argument('--epochs_phase1', type=int, default=50, help='Epochs for phase 1 (reconstruction)')
    parser.add_argument('--epochs_phase2', type=int, default=30, help='Epochs for phase 2 (detection + reconstruction)')
    parser.add_argument('--epochs_phase3', type=int, default=20, help='Epochs for phase 3 (classification)')
    
    # æ•°æ®é…ç½®
    parser.add_argument('--data_root', type=str, required=True, help='Root directory of dataset')
    parser.add_argument('--num_workers', type=int, default=4, help='Number of data loading workers')
    
    # æ£€æµ‹å™¨é…ç½®
    parser.add_argument('--yolo_model', type=str, default='yolo11n.pt', help='YOLO model path')
    parser.add_argument('--detection_conf', type=float, default=0.25, help='Detection confidence threshold')
    parser.add_argument('--detection_iou', type=float, default=0.45, help='Detection IoU threshold')
    parser.add_argument('--priority_boost', type=float, default=1.5, help='Priority boost for detected objects')
    parser.add_argument('--background_priority', type=float, default=0.1, help='Background priority')
    
    # è®­ç»ƒé…ç½®
    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints_detection', help='Checkpoint directory')
    parser.add_argument('--resume_from', type=str, default=None, help='Resume training from checkpoint')
    parser.add_argument('--device', type=str, default='cuda', help='Device to use')
    
    # æ—¥å¿—é…ç½®
    parser.add_argument('--wandb_project', type=str, default='LimitNet_Detection', help='Wandb project name')
    parser.add_argument('--wandb_name', type=str, default=None, help='Wandb run name')
    parser.add_argument('--log_every_n_steps', type=int, default=50, help='Log every n steps')
    
    return parser.parse_args()


def get_dataset(args):
    """è·å–æ•°æ®é›†"""
    if args.model == 'cifar':
        transform_train = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(degrees=15),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        transform_val = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        # æ£€æŸ¥æœ¬åœ°æ˜¯å¦å·²æœ‰æ•°æ®é›†
        cifar_path = os.path.join(args.data_root, 'cifar-100-python')
        download_needed = not os.path.exists(cifar_path)
        if download_needed:
            print("ğŸ“¥ æœ¬åœ°æœªæ‰¾åˆ°CIFAR-100æ•°æ®é›†ï¼Œå°†è‡ªåŠ¨ä¸‹è½½...")
        else:
            print("âœ… æ‰¾åˆ°æœ¬åœ°CIFAR-100æ•°æ®é›†ï¼Œè·³è¿‡ä¸‹è½½")
        
        train_dataset = torchvision.datasets.CIFAR100(
            root=args.data_root, train=True, download=download_needed, transform=transform_train
        )
        val_dataset = torchvision.datasets.CIFAR100(
            root=args.data_root, train=False, download=download_needed, transform=transform_val
        )
        
    elif args.model == 'imagenet':
        transform_train = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomResizedCrop(224),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        transform_val = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        train_dataset = torchvision.datasets.ImageFolder(
            root=os.path.join(args.data_root, 'train'), transform=transform_train
        )
        val_dataset = torchvision.datasets.ImageFolder(
            root=os.path.join(args.data_root, 'val'), transform=transform_val
        )
    
    train_loader = DataLoader(
        train_dataset, batch_size=args.batch_size, shuffle=True, 
        num_workers=args.num_workers, pin_memory=True, persistent_workers=True
    )
    val_loader = DataLoader(
        val_dataset, batch_size=args.batch_size, shuffle=False,
        num_workers=args.num_workers, pin_memory=True, persistent_workers=True
    )
    
    return train_loader, val_loader


def train_phase(model, train_loader, val_loader, phase, epochs, args):
    """è®­ç»ƒç‰¹å®šé˜¶æ®µ"""
    print(f"\n=== å¼€å§‹è®­ç»ƒé˜¶æ®µ {phase} ===")
    
    # è®¾ç½®æ¨¡å‹é˜¶æ®µ
    model.PHASE = phase
    
    # é…ç½®æ£€æŸ¥ç‚¹å’Œæ—¥å¿—
    checkpoint_callback = ModelCheckpoint(
        dirpath=os.path.join(args.checkpoint_dir, f'phase_{phase}'),
        filename=f'limitnet_detection_phase{phase}_' + '{epoch:02d}_{val_loss_avg_phase' + str(phase) + ':.3f}',
        monitor=f'val_loss_avg_phase{phase}',
        mode='min',
        save_top_k=3,
        save_last=True
    )
    
    lr_monitor = LearningRateMonitor(logging_interval='epoch')
    
    wandb_logger = WandbLogger(
        project=args.wandb_project,
        name=f"{args.wandb_name}_phase{phase}" if args.wandb_name else f"phase{phase}",
        save_dir=args.checkpoint_dir
    )
    
    # é…ç½®è®­ç»ƒå™¨
    trainer = L.Trainer(
        max_epochs=epochs,
        accelerator='gpu' if args.device == 'cuda' else 'cpu',
        devices=1,
        logger=wandb_logger,
        callbacks=[checkpoint_callback, lr_monitor],
        log_every_n_steps=args.log_every_n_steps,
        check_val_every_n_epoch=1,
        precision='16-mixed' if args.device == 'cuda' else 32,
        gradient_clip_val=1.0,
    )
    
    # å¼€å§‹è®­ç»ƒ
    trainer.fit(model, train_loader, val_loader)
    
    # ä¿å­˜é˜¶æ®µæ¨¡å‹
    phase_model_path = os.path.join(args.checkpoint_dir, f'limitnet_detection_phase{phase}_final.ckpt')
    trainer.save_checkpoint(phase_model_path)
    print(f"é˜¶æ®µ {phase} è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜è‡³: {phase_model_path}")
    
    return trainer.callback_metrics


def main():
    args = parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.checkpoint_dir, exist_ok=True)
    
    # è®¾ç½®è®¾å¤‡
    if args.device == 'cuda' and not torch.cuda.is_available():
        print("CUDAä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPU")
        args.device = 'cpu'
    
    # é…ç½®æ£€æµ‹å™¨
    detector_config = {
        'model_path': args.yolo_model,
        'conf_threshold': args.detection_conf,
        'iou_threshold': args.detection_iou,
        'device': args.device
    }
    
    print(f"ä½¿ç”¨è®¾å¤‡: {args.device}")
    print(f"æ£€æµ‹å™¨é…ç½®: {detector_config}")
    
    # è·å–æ•°æ®
    print("å‡†å¤‡æ•°æ®é›†...")
    train_loader, val_loader = get_dataset(args)
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_loader.dataset)}")
    print(f"éªŒè¯é›†å¤§å°: {len(val_loader.dataset)}")
    
    # åˆ›å»ºæ¨¡å‹
    print("åˆå§‹åŒ–æ¨¡å‹...")
    model = LimitNetWithDetection(
        model_type=args.model,
        detector_config=detector_config
    )
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¢å¤è®­ç»ƒæˆ–åŠ è½½é¢„è®­ç»ƒæƒé‡
    start_phase = 1
    if args.resume_from and os.path.exists(args.resume_from):
        print(f"ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {args.resume_from}")
        try:
            # å°è¯•åŠ è½½Lightningæ£€æŸ¥ç‚¹
            model = LimitNetWithDetection.load_from_checkpoint(
                args.resume_from,
                model_type=args.model,
                detector_config=detector_config
            )
            print("âœ… æˆåŠŸåŠ è½½Lightningæ£€æŸ¥ç‚¹")
        except Exception as e:
            print(f"Lightningæ£€æŸ¥ç‚¹åŠ è½½å¤±è´¥: {e}")
            try:
                # å°è¯•åŠ è½½æ™®é€šPyTorchæ¨¡å‹
                checkpoint = torch.load(args.resume_from, map_location=args.device)
                if 'state_dict' in checkpoint:
                    model.load_state_dict(checkpoint['state_dict'])
                    print("âœ… æˆåŠŸåŠ è½½PyTorchçŠ¶æ€å­—å…¸")
                    if 'transfer_info' in checkpoint:
                        print("ğŸ”„ æ£€æµ‹åˆ°æƒé‡è¿ç§»ä¿¡æ¯:")
                        print(f"  åŸå§‹æ¨¡å‹: {checkpoint['transfer_info'].get('original_model_path', 'æœªçŸ¥')}")
                        print(f"  è¿ç§»ç»„ä»¶: {checkpoint['transfer_info'].get('transferred_components', [])}")
                else:
                    print("âŒ æ— æ³•è¯†åˆ«çš„æ¨¡å‹æ ¼å¼")
            except Exception as e2:
                print(f"PyTorchæ¨¡å‹åŠ è½½ä¹Ÿå¤±è´¥: {e2}")
                print("å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹")
    
    # ä¸‰é˜¶æ®µè®­ç»ƒ
    phases_config = [
        (1, args.epochs_phase1, "é‡å»ºè®­ç»ƒ"),
        (2, args.epochs_phase2, "æ£€æµ‹+é‡å»ºè®­ç»ƒ"), 
        (3, args.epochs_phase3, "åˆ†ç±»è®­ç»ƒ")
    ]
    
    for phase, epochs, description in phases_config[start_phase-1:]:
        print(f"\n{'='*50}")
        print(f"é˜¶æ®µ {phase}: {description}")
        print(f"è®­ç»ƒè½®æ•°: {epochs}")
        print(f"{'='*50}")
        
        try:
            metrics = train_phase(model, train_loader, val_loader, phase, epochs, args)
            print(f"é˜¶æ®µ {phase} å®Œæˆï¼Œæœ€ç»ˆæŒ‡æ ‡: {metrics}")
            
        except KeyboardInterrupt:
            print(f"\nè®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜å½“å‰æ¨¡å‹...")
            interrupted_path = os.path.join(args.checkpoint_dir, f'interrupted_phase{phase}.ckpt')
            torch.save(model.state_dict(), interrupted_path)
            print(f"æ¨¡å‹å·²ä¿å­˜è‡³: {interrupted_path}")
            break
        except Exception as e:
            print(f"é˜¶æ®µ {phase} è®­ç»ƒå‡ºé”™: {str(e)}")
            break
    
    print("\nè®­ç»ƒå®Œæˆ!")
    final_model_path = os.path.join(args.checkpoint_dir, 'limitnet_detection_final.ckpt')
    torch.save(model.state_dict(), final_model_path)
    print(f"æœ€ç»ˆæ¨¡å‹ä¿å­˜è‡³: {final_model_path}")


if __name__ == "__main__":
    main() 